#!/bin/bash

# Exit on any error
set -e

# Create logs directory if it doesn't exist
mkdir -p logs

echo "ğŸš€ Uruchamianie Asystenta AI z GPU Acceleration..."

# GPU-optimized environment variables for Ollama
export OLLAMA_MAX_LOADED_MODELS=1
export OLLAMA_NUM_PARALLEL=1
export OLLAMA_GPU_OVERHEAD=0
export CUDA_VISIBLE_DEVICES=0

# Function to kill existing processes
kill_existing_processes() {
    echo "ğŸ” Sprawdzanie i zatrzymywanie aktywnych procesÃ³w..."
    
    # Kill Django processes on port 8000
    lsof -t -i:8000 | xargs -r kill -9 2>/dev/null || true
    
    # Kill manage.py processes
    pkill -f "python.*manage.py.*runserver" 2>/dev/null || true
    
    # Kill Celery worker processes
    pkill -f "celery.*worker" 2>/dev/null || true
    
    echo "âœ… Poprzednie procesy zatrzymane"
}

# Function to start the message broker (Valkey/Redis)
start_broker() {
    echo "ğŸ“¦ Sprawdzanie brokera wiadomoÅ›ci (Valkey/Redis)..."
    if systemctl is-active --quiet valkey.service; then
        echo "âœ… Valkey (Redis) jest juÅ¼ uruchomiony."
    else
        echo "ğŸ”„ PrÃ³ba uruchomienia Valkey... (moÅ¼e wymagaÄ‡ hasÅ‚a sudo)"
        sudo systemctl start valkey
        sleep 2
        if systemctl is-active --quiet valkey.service; then
            echo "âœ… Valkey uruchomiony pomyÅ›lnie."
        else
            echo "âŒ Nie udaÅ‚o siÄ™ uruchomiÄ‡ Valkey. SprÃ³buj rÄ™cznie: sudo systemctl start valkey"
            exit 1
        fi
    fi
}

# Function to check GPU and setup Ollama
setup_gpu_environment() {
    echo "ğŸ¯ Sprawdzanie Å›rodowiska GPU..."
    
    if command -v nvidia-smi &> /dev/null; then
        GPU_INFO=$(nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits | head -1)
        echo "ğŸš€ Wykryto GPU: $GPU_INFO"
        
        # First, check if Ollama is responsive
        if curl -s http://127.0.0.1:11434/api/tags &> /dev/null; then
            echo "âœ… Ollama juÅ¼ dziaÅ‚a."
            return
        fi

        # If not responsive, kill any existing processes and start fresh
        echo "âš ï¸ Ollama nie odpowiada. PrÃ³ba restartu..."
        pkill -f "ollama serve" 2>/dev/null || true
        sleep 2

        echo "ğŸ”„ Uruchamianie Ollama w tle..."
        nohup ollama serve > logs/ollama.log 2>&1 &
        sleep 3
        
        # Wait for Ollama to start
        for i in {1..10}; do
            if curl -s http://127.0.0.1:11434/api/tags &> /dev/null; then
                echo "âœ… Ollama uruchomione pomyÅ›lnie."
                return
            fi
            echo "â³ Oczekiwanie na Ollama... ($i/10)"
            sleep 2
        done
        
        echo "âŒ Nie udaÅ‚o siÄ™ uruchomiÄ‡ Ollama po restarcie."
        exit 1
    else
        echo "ğŸ’» Brak GPU NVIDIA - uÅ¼ywanie CPU"
    fi
}

# Function to verify required models
verify_models() {
    echo "ğŸ¤– Sprawdzanie dostÄ™pnoÅ›ci modeli AI..."
    
    if ! curl -s http://127.0.0.1:11434/api/tags &> /dev/null; then
        echo "âš ï¸  Ollama niedostÄ™pne - pomijam sprawdzanie modeli."
        return
    fi
    
    MODELS=$(curl -s http://127.0.0.1:11434/api/tags | python3 -c "import json, sys; print(' '.join([m['name'] for m in json.load(sys.stdin).get('models', [])]))" 2>/dev/null || echo "")
    REQUIRED_MODELS=("qwen2:7b" "mistral:7b" "qwen2.5vl:7b")
    MISSING_MODELS=()
    
    for model in "${REQUIRED_MODELS[@]}"; do
        if [[ ! " $MODELS " =~ " $model " ]]; then
            MISSING_MODELS+=("$model")
        fi
    done
    
    if [ ${#MISSING_MODELS[@]} -eq 0 ]; then
        echo "âœ… Wszystkie wymagane modele AI dostÄ™pne."
    else
        echo "âš ï¸  BrakujÄ…ce modele: ${MISSING_MODELS[*]}"
        echo "ğŸ’¡ Pobierz je uÅ¼ywajÄ…c: ollama pull <model_name>"
    fi
}

# Main execution
echo "ğŸ§¹ Czyszczenie poprzednich sesji..."
kill_existing_processes

echo "---"
start_broker
echo "---"
setup_gpu_environment
echo "---"

echo "ğŸ Aktywowanie Å›rodowiska wirtualnego..."
source .venv/bin/activate

echo "ğŸ—„ï¸  Stosowanie migracji bazy danych..."
.venv/bin/python manage.py migrate

echo "---"

# Function to setup frontend assets
setup_frontend_assets() {
    echo "ğŸ¨ Konfiguracja zasobÃ³w frontendowych (Tailwind CSS + Alpine.js)..."

    # Check if Node.js and npm are available
    if command -v node &> /dev/null && command -v npm &> /dev/null; then
        echo "ğŸ“¦ Sprawdzanie zaleÅ¼noÅ›ci Node.js..."

        # Check if package.json exists
        if [ -f "package.json" ]; then
            # Install npm dependencies if node_modules doesn't exist
            if [ ! -d "node_modules" ]; then
                echo "â¬‡ï¸  Instalowanie zaleÅ¼noÅ›ci npm..."
                npm install
                if [ $? -eq 0 ]; then
                    echo "âœ… ZaleÅ¼noÅ›ci npm zainstalowane pomyÅ›lnie"
                else
                    echo "âŒ BÅ‚Ä…d podczas instalacji zaleÅ¼noÅ›ci npm"
                    exit 1
                fi
            else
                echo "âœ… ZaleÅ¼noÅ›ci npm juÅ¼ zainstalowane"
            fi

            # Build Tailwind CSS assets
            echo "ğŸ¨ Kompilowanie Tailwind CSS..."
            if npm run build-css 2>/dev/null; then
                npm run build-css
                if [ $? -eq 0 ]; then
                    echo "âœ… Tailwind CSS skompilowany pomyÅ›lnie"
                else
                    echo "âŒ BÅ‚Ä…d podczas kompilacji Tailwind CSS"
                    exit 1
                fi
            else
                echo "âš ï¸  Brak skryptu build-css, uÅ¼ywam ogÃ³lnego build..."
                npm run build
                if [ $? -eq 0 ]; then
                    echo "âœ… Zasoby frontendowe skompilowane pomyÅ›lnie"
                else
                    echo "âŒ BÅ‚Ä…d podczas kompilacji zasobÃ³w frontendowych"
                    exit 1
                fi
            fi
        else
            echo "â„¹ï¸  Brak pliku package.json - pomijam instalacjÄ™ npm"
        fi
    else
        echo "â„¹ï¸  Node.js nie jest dostÄ™pny - pomijam konfiguracjÄ™ frontend"
    fi
}

# Function to collect Django static files
collect_static_files() {
    echo "ğŸ“ Zbieranie plikÃ³w statycznych Django..."

    # Create static directory if it doesn't exist
    mkdir -p chatbot/static
    mkdir -p inventory/static

    # Collect static files
    .venv/bin/python manage.py collectstatic --noinput --clear
    if [ $? -eq 0 ]; then
        echo "âœ… Pliki statyczne Django zebrane pomyÅ›lnie"
    else
        echo "âŒ BÅ‚Ä…d podczas zbierania plikÃ³w statycznych"
        exit 1
    fi
}

setup_frontend_assets
echo "---"
collect_static_files
echo "---"
verify_models
echo "---"

echo "ğŸ‘· Uruchamianie workera Celery w tle..."
nohup .venv/bin/celery -A core.celery_app worker -l info > logs/celery.log 2>&1 &
sleep 2 # Give celery time to start
echo "âœ… Worker Celery uruchomiony. Logi w: logs/celery.log"

echo "ğŸŒ Uruchamianie serwera WebSocket (Daphne) w tle..."
nohup .venv/bin/daphne core.asgi:application -b 0.0.0.0 -p 8000 > logs/daphne.log 2>&1 &
sleep 2 # Give daphne time to start
echo "âœ… Serwer WebSocket uruchomiony. Logi w: logs/daphne.log"



echo ""
echo "ğŸ‰ Wszystkie usÅ‚ugi zostaÅ‚y uruchomione w tle! ğŸ‰"
echo ""
echo "â¡ï¸  Aplikacja Django jest dostÄ™pna pod adresem: http://127.0.0.1:8000"
echo "â¡ï¸  Logi Django znajdziesz w pliku: tail -f logs/django.log"
echo "â¡ï¸  Logi Celery znajdziesz w pliku: tail -f logs/celery.log"
echo ""
echo "ğŸ”´ Aby zatrzymaÄ‡ wszystkie usÅ‚ugi, uruchom:"
echo "   pkill -f 'manage.py runserver' && pkill -f 'celery.*worker' && sudo systemctl stop valkey"
echo ""
